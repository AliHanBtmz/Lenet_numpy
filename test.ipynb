{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e035f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e406d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5)\n",
    "\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = torch.tanh(self.conv3(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ef9aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42652999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=True, download=False, transform=transforms\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"data\", train=False, download=False, transform=transforms\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15361e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9edae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7faa2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loader.dataset)}]  Loss: {loss.item():.4f}'\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9de66d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss_total += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "            total += target.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(\n",
    "        f\"\\nTest set: Average loss: {loss_total / len(loader):.4f}, Accuracy: {correct}/{total} ({accuracy:.2f}%)\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7da1cb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000]  Loss: 2.3146'\n",
      "Train Epoch: 1 [6400/60000]  Loss: 0.3925'\n",
      "Train Epoch: 1 [12800/60000]  Loss: 0.1681'\n",
      "Train Epoch: 1 [19200/60000]  Loss: 0.2605'\n",
      "Train Epoch: 1 [25600/60000]  Loss: 0.1034'\n",
      "Train Epoch: 1 [32000/60000]  Loss: 0.1268'\n",
      "Train Epoch: 1 [38400/60000]  Loss: 0.2403'\n",
      "Train Epoch: 1 [44800/60000]  Loss: 0.1446'\n",
      "Train Epoch: 1 [51200/60000]  Loss: 0.2352'\n",
      "Train Epoch: 1 [57600/60000]  Loss: 0.0561'\n",
      "\n",
      "Test set: Average loss: 0.1137, Accuracy: 9664/10000 (96.64%)\n",
      "\n",
      "Train Epoch: 2 [0/60000]  Loss: 0.1448'\n",
      "Train Epoch: 2 [6400/60000]  Loss: 0.1439'\n",
      "Train Epoch: 2 [12800/60000]  Loss: 0.0761'\n",
      "Train Epoch: 2 [19200/60000]  Loss: 0.0549'\n",
      "Train Epoch: 2 [25600/60000]  Loss: 0.0461'\n",
      "Train Epoch: 2 [32000/60000]  Loss: 0.0968'\n",
      "Train Epoch: 2 [38400/60000]  Loss: 0.0147'\n",
      "Train Epoch: 2 [44800/60000]  Loss: 0.0924'\n",
      "Train Epoch: 2 [51200/60000]  Loss: 0.1209'\n",
      "Train Epoch: 2 [57600/60000]  Loss: 0.0324'\n",
      "\n",
      "Test set: Average loss: 0.0691, Accuracy: 9769/10000 (97.69%)\n",
      "\n",
      "Train Epoch: 3 [0/60000]  Loss: 0.0438'\n",
      "Train Epoch: 3 [6400/60000]  Loss: 0.1118'\n",
      "Train Epoch: 3 [12800/60000]  Loss: 0.0302'\n",
      "Train Epoch: 3 [19200/60000]  Loss: 0.0714'\n",
      "Train Epoch: 3 [25600/60000]  Loss: 0.0072'\n",
      "Train Epoch: 3 [32000/60000]  Loss: 0.0668'\n",
      "Train Epoch: 3 [38400/60000]  Loss: 0.0435'\n",
      "Train Epoch: 3 [44800/60000]  Loss: 0.0237'\n",
      "Train Epoch: 3 [51200/60000]  Loss: 0.0236'\n",
      "Train Epoch: 3 [57600/60000]  Loss: 0.0894'\n",
      "\n",
      "Test set: Average loss: 0.0573, Accuracy: 9824/10000 (98.24%)\n",
      "\n",
      "Train Epoch: 4 [0/60000]  Loss: 0.1299'\n",
      "Train Epoch: 4 [6400/60000]  Loss: 0.0534'\n",
      "Train Epoch: 4 [12800/60000]  Loss: 0.0219'\n",
      "Train Epoch: 4 [19200/60000]  Loss: 0.1038'\n",
      "Train Epoch: 4 [25600/60000]  Loss: 0.0352'\n",
      "Train Epoch: 4 [32000/60000]  Loss: 0.0179'\n",
      "Train Epoch: 4 [38400/60000]  Loss: 0.0248'\n",
      "Train Epoch: 4 [44800/60000]  Loss: 0.0445'\n",
      "Train Epoch: 4 [51200/60000]  Loss: 0.1074'\n",
      "Train Epoch: 4 [57600/60000]  Loss: 0.0654'\n",
      "\n",
      "Test set: Average loss: 0.0575, Accuracy: 9816/10000 (98.16%)\n",
      "\n",
      "Train Epoch: 5 [0/60000]  Loss: 0.0358'\n",
      "Train Epoch: 5 [6400/60000]  Loss: 0.1357'\n",
      "Train Epoch: 5 [12800/60000]  Loss: 0.0158'\n",
      "Train Epoch: 5 [19200/60000]  Loss: 0.0369'\n",
      "Train Epoch: 5 [25600/60000]  Loss: 0.0204'\n",
      "Train Epoch: 5 [32000/60000]  Loss: 0.0534'\n",
      "Train Epoch: 5 [38400/60000]  Loss: 0.0393'\n",
      "Train Epoch: 5 [44800/60000]  Loss: 0.1144'\n",
      "Train Epoch: 5 [51200/60000]  Loss: 0.0406'\n",
      "Train Epoch: 5 [57600/60000]  Loss: 0.0156'\n",
      "\n",
      "Test set: Average loss: 0.0531, Accuracy: 9828/10000 (98.28%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6):\n",
    "    train(model, train_loader, optimizer, criterion, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "982f3606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.eye(5)[[0, 1, 2, 3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2100d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.zeros((5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a7041034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  5,  6,  4,  8,  0,  0],\n",
       "       [ 0,  0,  4, 50,  3,  8,  7,  0,  0],\n",
       "       [ 0,  0,  8,  5,  7,  4,  6,  0,  0],\n",
       "       [ 0,  0,  5,  8,  4,  6, 50,  0,  0],\n",
       "       [ 0,  0,  5,  8,  7,  3,  6,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = [\n",
    "    [1, 5, 6, 4, 8],\n",
    "    [4, 50, 3, 8, 7],\n",
    "    [8, 5, 7, 4, 6],\n",
    "    [5, 8, 4, 6, 50],\n",
    "    [5, 8, 7, 3, 6],\n",
    "]\n",
    "ali = np.array(ali)\n",
    "input_data = np.pad(\n",
    "    ali,\n",
    "    ((2, 2), (2, 2)),\n",
    "    mode=\"constant\",\n",
    ")\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2c409ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26893591, 0.43317502, 0.24489025],\n",
       "       [0.91335232, 0.32527073, 0.21255412],\n",
       "       [0.5421353 , 0.88998036, 0.60753343],\n",
       "       [0.60526387, 0.58623704, 0.60068163],\n",
       "       [0.55316899, 0.70345836, 0.69884117],\n",
       "       [0.77744044, 0.22255925, 0.63761264],\n",
       "       [0.08826618, 0.26424135, 0.98133608],\n",
       "       [0.15872941, 0.58845439, 0.96665832]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.rand(8, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5dec2af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.ones((1, 3))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "51324bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = [1, 2, 3, 7, 9, 5, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "021eb688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.2303417 , 17.74238849, 20.08965664]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.dot(input_, a) + b\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "559b6749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ali = [[2, 5], [8, 9]]\n",
    "ali = np.expand_dims(ali, 0)\n",
    "ali.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ae0478d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 8, 9]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tav = ali.reshape(ali.shape[0], -1)\n",
    "tav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162af006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
